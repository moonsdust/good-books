---
title: "Differences in Homicide Case Characteristics Indicates Why Justice is Not Served"
subtitle: "An analysis of solved and unsolved homicides from 2010 to 2017 in the United States's 2 largest cities, New York and Los Angeles"
author: 
  - Emily Su
thanks: "Code and data are available at: [https://github.com/moonsdust/unsolved-murders](https://github.com/moonsdust/unsolved-murders)."
date: today
date-format: long
abstract: "First sentence. Second sentence. Third sentence. Fourth sentence."
format:
  pdf:
    toc: true
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(arrow)
library(ggplot2)
library(modelsummary)
library(rstanarm)
library(dplyr)
library(knitr)
library(car)
library(DiagrammeR)
library(rsvg)
library(DiagrammeRsvg)
library(png)

# Read in analysis data
analysis_data_homicides <- read_parquet("../data/02-analysis_data/cleaned_data_homicides.parquet")
# Read in model data
unsolved_model_results <- readRDS("../models/unsolved_homicide_model.rds")
```

# Introduction

Overview paragraph

This led to us investigate the following question in our paper: what are the differences in homicide case information like the year and city the homicide took place and the victims’ perceived characteristics (age, sex, and race) between solved and unsolved homicides in 2 of the largest cities in the United States, New York and Los Angeles, from 2010 to 2017?

Estimand paragraph

Results paragraph

Why it matters paragraph

Telegraphing paragraph: The remainder of this paper is structured as follows. @sec-data....






# Data {#sec-data}

## Overview

The dataset we used for this paper comes from The Washington's Post's GitHub repository, "How The Post mapped unsolved murders", which is also known as the "Unsolved Homicide Database" [@datahomicides]. We used the statistical programming language R [@citeR], tidyverse [@citetidyverse], janitor [@citejanitor], lubridate [@citelubridate], dplyr [@citedplyr], ggplot2 [@citeggplot2], arrow [@citearrow], testthat [@citetestthat], and knitr [@citeknitr] to retrieve, clean, test, and analyze the dataset. To construct, test, and analyze our model, we used the following packages: rstanarm [@citerstanarm], modelsummary [@citemodelsummary], and car [@citecar]. The causal model diagram created to understand the relationship between predictor variables, the outcome variable, and a confounder used DiagrammeR [@citeDiagrammeR], rsvg [@citersvg], DiagrammeRsvg [@citeDiagrammeRsvg] and png [@citepng]. To style our scripts, we used lintr [@citelintr] and styler [@citestyler]. 

The Washington Post's Unsolved Homicide Database is a dataset compiled by Washington Post reporters that contains over 52000 homicides in the United States (US) from 50 of the largest US cities from 2007 to 2017 [@datahomicides]. This dataset includes information about the victim such as their name, sex, race, and age as well as geographic and temporal information of the homicide. The Washington Post was interested in using the information compiled to map unsolved homicides across the United States in major cities from 2007 to 2017 [@citewashingtonpostmap]. Another dataset we had considered using was another one compiled by The Washington Post on school shootings across the US and approaching our problem with a different perspective on the characteristics of the perpetrator. However, due to there only being 416 observations and numerous observations missing information, we forgo using the dataset. 

The raw dataset we retrieved from The Washington Post using a script that downloads the CSV file from their GitHub repository contains 52179 observations with one observation being a homicide case. However, since we narrowed our scope to focus on the two of the most populated US cities, Los Angeles and New York, the number of observations in our cleaned dataset ended up being 2820. Our data look as follows: 

```{r}
#| label: tbl-dataset-preview
#| tbl-cap: Preview of dataset on solved and unsolved homicides (2010 to 2017) with the original dataset compiled by The Washington Post 
#| echo: false
#| warning: false
#| message: false

# Create table to display dataset
analysis_data_homicides |>
  head() |>
  kable()
```

```{r}
#| label: tbl-dataset-statistics
#| tbl-cap: Number of observations, minimum, maximum, median, mean, 1st and 3rd quartile of variables in dataset on solved and unsolved homicides (2010 to 2017) excluding victim_sex, city, and disposition
#| echo: false
#| warning: false
#| message: false

# Create table to display summary statistics
analysis_data_homicides |>
  select(-c(city, victim_sex, disposition)) |>
  summary() |>
  kable()
```

@tbl-dataset-preview and @tbl-dataset-statistics indicates our variables of interest, which are the following: victim_race, victim_age, victim_sex, city, disposition, year, month, and arrest_was_not_made. victim_race represents the race of the homicide victim, which can be "White" (248 observations), "Hispanic" (1242 observations), "Black" (1216 observations), "Asian" (58 observations), and "Other" (56 observations). victim_age signifies the age of the homicide victim at the time of their death and is defined as a whole number. @tbl-dataset-statistics reveals that the mean victim_sex is the sex of the homicide victim where they are either identified as a "female" or "male". The city variable defines the city the victim is reported to have been found in. The disposition variable is the specific status of a homicide case where a case can fall in either of the following three status: "Closed by arrest", "Open/No arrest", and "Closed without arrest". The year variable represents a year from 2010 to 2017 that indicates the year the homicide took place. Following this, the month variable represents the month a homicide took place. arrest_was_not_made is a variable that was constructed based on the disposition variable with "Closed by arrest" being converted to a 0 and "Open/No arrest" and "Closed without arrest" being converted to a 1. arrest_was_not_made indicates the status of a homicide case as either being unsolved, which is denoted by a 1, and solved, which is denoted by a 0. 

However, our dataset has limitations. There was only data available from 2010 onwards for both New York and Los Angeles provided by The Washington Post and so that limited the number of homicides we could look at. Also, not all victims were able to be identified in some homicide cases and unknown attributes of the victim such as their age, sex, and gender were indicated with the text "Unknown" in the dataset. However, this causes issues with data type compatibility such as the value "Unknown" being a character type being under the victim_age column, which has a data type of integer. This would lead to issues with our model providing accurate estimates. We decided to remove cases during our data cleaning where victim's demographic information is missing at least one of the three columns, victim_age, victim_sex, victim_race. 

## Measurement

- TODO: A thorough discussion of measurement, relating to the dataset, is provided in the data section. Please ensure that you explain how we went from some phenomena in the world that happened to an entry in the dataset that you are interested in.

Some paragraphs about how we go from a phenomena in the world to an entry in the dataset.

- How homicide cases are recorded by the New York Police and Los Angeles Police 
- How The Washington Post obtain the data and what did they do



## Outcome variable

## Predictor variables
The variables, disposition and month are not predictor variables in our model but they are used to investigate trends between homicide case information and the status of the homicide being solved or unsolved. 




\newpage

# Model {#sec-model}
The model we implemented was a Bayesian logistic regression model. This model was constructed after we saw patterns between homicide case information and a homicide case going unsolved in our analysis. We are interested in seeing if certain characteristics of a homicide case such as the victim's perceived characteristics (sex, gender, age) and the year and city the victim is found impacts the likelihood of their case going unsolved. 

## Model set-up
With our model, we will make the assumption that there is a relationship between homicide case information like the victim's race, victim's age, victim's sex, the city, and the year with a homicide case being unsolved. We also assume that the predictor variables are independent from one another, which we check in @sec-model-details using variance inflation factor (VIF) and it indicates the predictors are not highly correlated with each other. We define our model as follows:

\begin{align*}
y_i|\pi_i &\sim \mbox{Bern}(\pi_i) \\
\mbox{logit}(\pi_i) &= \beta_0 + \beta_1 \times \mbox{victim\_race}_i + \beta_2 \times \mbox{victim\_age}_i + \beta_3 \times \mbox{victim\_sex}_i + \beta_4 \times \mbox{city}_i + \beta_5 \times \mbox{year}_i\\
\beta_0 &\sim \mbox{Normal}(0, 2.5) \\
\beta_1 &\sim \mbox{Normal}(0, 2.5) \\
\beta_2 &\sim \mbox{Normal}(0, 2.5) \\
\beta_3 &\sim \mbox{Normal}(0, 2.5) \\
\beta_4 &\sim \mbox{Normal}(0, 2.5) \\
\beta_5 &\sim \mbox{Normal}(0, 2.5)
\end{align*}

We define $y_i$ to be the status of the homicide case where 1 means the homicide is unsolved (case is still open / been closed without arrest) and 0 means the homicide is solved (case has been closed with arrest). $\pi_i$ represents the probability of the homicide being solved. $\mbox{logit}(\pi_i)$ indicates the log-odds of the homicide being unsolved. Now looking at the coefficients $b_i$ and predictor variables, $\beta_0$ is the intercept of our model and is the log-odds when all predictor variables are equal to 0. $\mbox{victim\_race}_i$ signifies the race of the victim, which could be either "Asian", "Black", "Hispanic", "White", and "Other". In our model, we use "White" as the baseline for $\mbox{victim\_race}_i$ to see if being part of a minority impacts if the case goes unsolved or not. $\beta_1$ is the coefficient that represents the log-odds when $\mbox{victim\_race}_i$ changes. $\mbox{victim\_age}_i$ is the victim's age, which is a whole number. $\beta_2$ is the log-odds when $\mbox{victim\_age}_i$ increases by 1 year. $\mbox{victim\_sex}_i$ represents the sex of the victim, where in the dataset it is either "female" or "male" and $\beta_3$ is the log-odds when $\mbox{victim\_sex}_i$ changes. $\mbox{city}_i$ is the city the victim was reported to be killed in, which from our dataset could be either "New York" or "Los Angeles". $\beta_4$ is the coefficient that stands for the log-odds when $\mbox{city}_i$ changes. We define $\mbox{year}_i$ to be the year the homicide was reported to have occured from 2010 to 2017. $\beta_5$ indicates the log-odds when $\mbox{year}_i$ increases by 1 year.

Our model runs in R [@citeR] using the rstanarm package [@citerstanarm]. For our model's priors, we use the default priors provided by rstanarm [@citerstanarm]. Diagnostics for the model such as in posterior predictive check, posterior versus prior comparison, trace and Rhat plots can be found in @sec-model-details.

## Model justification

We used a logistic regression model in a Bayesian framework due to the fact that our outcome is binary and predicts if a homicide is unsolved or not. Another model we considered is a logistic regression model with an instrumental variable. Introducing a instrumental variable into our model could have potentially provided a more accurate model and given us more consistent coefficient estimates as noted by @citeucdavis. However with the available information we had about each case, there was no candidate instrumental variable that impacted at least one variable in our data and not influence the outcome of the case being solved or unsolved. Thus, the model would fail the "Exclusion Restriction" assumption mentioned by @citetellingstories. We also went through different pairs and groupings of variables and how there was not a strong relationship between variables that is relevant and consequently fail @citetellingstories's "Relevance" assumption. We also have known treatment variable/predictor variables that can be used to measure the outcome variable and therefore, the instrumental variable is less likely to be necessary [@citetellingstories].

In our model, we assumed there is a relationship between the outcome variable, homicide is unsolved, with homicide case information like demographic (sex, race, and age of victim), geographic (city), and temporal (year) information, which are the predictor variables. For the demographic data, we decided to keep the grouping provided by The Washington Post such as for sex it was "female" and "male" and race it was "White", "Black", "Hispanic", "Asian", and "Other. However, we did remove victims who has any demographic information that falls under the "Unknown" grouping from our dataset and did not run our regression model on these observations. The reason for this is due to factors such as the data type of the predictor and keeping consistency across all observation and removing any unknown values. For example, our predictor variable, victim's age is a integer data type but it contained the string "Unknown" in the raw dataset. So the values "Unknown" is removed in our final dataset and not used to train our model. Since our outcome variable is binary for our model, we constructed the arrest_was_not_made column for it based on the disposition variable to reflect it and considered dispositions with values like "Open/No arrest" and "Closed without arrest" to be 1 and "Closed by arrest" to be 0.   

Performing root mean square deviation (RSME) calculations on our model in @tbl-model-result yields a RSME value of about 0.49. RSME represents the difference between the model's predicted values and observed values with 0 meaning that the predicted and observed values are the same [@citejim]. Since the model's RSME value is close to 0, we can say our model is able to predict values with less error compared to other models that have a higher RSME value. 

```{r}
#| label: fig-causal-model
#| fig-cap: Causal relationship between homicide case information and homicide case being unsolved 
#| echo: false
#| warning: false
#| message: false

# Referenced code from: https://stackoverflow.com/questions/42737645/how-to-export-images-of-diagrammer-in-r and https://www.erikigelstrom.com/articles/causal-graphs-in-r-with-diagrammer/
causal_model <- "digraph { graph []
  # Nodes
  node [shape = plaintext]
    A [label = 'Case being unsolved']
    B [label = 'Race of victim']
    C [label = 'Age of victim']
    D [label = 'Sex of victim']
    E [label = 'City']
    F [label = 'Date (Year)']
    G [label = 'Resources of investigating team (Confounder)']
  edge []
    B->A
    C->A
    D->A
    E->A
    F->A
{ rank = same; }
  # Confounding variables's edges 
  edge [style = dashed]
    G -> A
    G -> E
    G -> F
}"
# Export diagram as a png
exporting_image <- grViz(causal_model) |>
  export_svg() |>
  charToRaw() |>
  rsvg_png("../other/sketches/casual_model.png", width = 1000)

# NOTE: Needed to save diagram and read it in as an image since grViz doesn't render in PDFs
# Referenced https://stackoverflow.com/questions/23861000/displaying-images-in-r-in-version-3-1-0
the_image <- readPNG("../other/sketches/casual_model.png")
plot.new()
rasterImage(the_image, 0,0,1.05,1)
```

However, our model has limitations and there are situations where this model would not work. @fig-causal-model shows that there is a confounder, "resources of investigating team" between the predictor variables, city and year and the outcome variable, case being unsolved. We define "resources of the investigating team" to include any of the following: the amount of people on the team investigating the case, time available allotted to investigate the case, amount of open cases for the team, cost, skill and education levels of members, etc. We currently do not have any information available about the resources of the investigating team for the case and further investigation is needed. We proposed an idealized survey we would conduct to collect the necessary data to further understand the relationship between homicide case characteristics and unsolved homicides in @sec-ideal-survey. If we have information available about the resources of the investigating team for the case, the current model would not work and would need to be revised. This is due to the interaction between the city, year, and outcome variables with the confounder.  

\newpage

# Results {#sec-results}

## Differences in Homicide Case Information Between Solved and Unsolved Cases in New York and Los Angeles (2010 to 2017)

### Date (Month and Year)
```{r}
#| label: fig-month-bar
#| fig-cap: "Number of solved and unsolved homicides across the 12 months of a year in Los Angeles and New York (2010 to 2017)"
#| echo: false
#| warning: false
#| message: false

number_of_cases_month <- 
  analysis_data_homicides |>
  # Group by solved and unsolved homicides 
  group_by(arrest_was_not_made) |>
  # Count number of solved and unsolved homicides for each month
  count(month)|>
  # Rename count column
  rename(
    "num_of_cases_month" = n
  ) |>
  mutate(
    month = case_when(
      (month == 1) ~ "Jan",
      (month == 2) ~ "Feb",
      (month == 3) ~ "Mar",
      (month == 4) ~ "Apr",
      (month == 5) ~ "May",
      (month == 6) ~ "Jun",
      (month == 7) ~ "Jul",
      (month == 8) ~ "Aug",
      (month == 9) ~ "Sep",
      (month == 10) ~ "Oct",
      (month == 11) ~ "Nov",
      (month == 12) ~ "Dec",
      TRUE ~ "None")
  ) |>
  mutate(
    arrest_was_not_made = case_when(
      (arrest_was_not_made == 1) ~ "Arrest was not made",
      (arrest_was_not_made == 0) ~ "Arrest was made",
      TRUE ~ "None")
  )

# To sort month in certain order 
# Referenced: https://www.geeksforgeeks.org/how-to-put-x-axis-in-order-month-in-r/ for code
number_of_cases_month$month <- factor(number_of_cases_month$month, levels = c('Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'))

number_of_cases_month |>
  ggplot(mapping = aes(x = month, y = num_of_cases_month)) +
  # Creates two graphs based on the status of the case
  facet_wrap(facets = vars(arrest_was_not_made), dir = "v") +
  geom_bar(stat = "identity", fill = "#a4ac86") +
  theme_minimal() +
  labs(x = "Month of the year", y = "Number of homicide cases") +
  theme(legend.position = "bottom")
```

```{r}
#| label: fig-year-bar
#| fig-cap: "Number of solved and unsolved homicides from 2010 to 2017 in Los Angeles and New York"
#| echo: false
#| warning: false
#| message: false

number_of_cases_year <- 
  analysis_data_homicides |>
  # Group by solved and unsolved homicides 
  group_by(arrest_was_not_made) |>
  # Count number of solved and unsolved homicides for each year
  count(year)|>
  # Rename count column
  rename(
    "num_of_cases_year" = n
  ) |>
  mutate(
    arrest_was_not_made = case_when(
      (arrest_was_not_made == 1) ~ "Arrest was not made",
      (arrest_was_not_made == 0) ~ "Arrest was made",
      TRUE ~ "None")
  )

number_of_cases_year |>
  ggplot(mapping = aes(x = as.character(year), y = num_of_cases_year)) +
  # Creates two graphs based on the status of the case
  facet_wrap(facets = vars(arrest_was_not_made), dir = "v") +
  geom_bar(stat = "identity", fill = "#a4ac86") +
  theme_minimal() +
  labs(x = "Year", y = "Number of homicide cases") +
  theme(legend.position = "bottom")
```

```{r}
#| label: fig-year-month-heatmap
#| fig-cap: "Number of solved and unsolved homicides from January to December from 2010 to 2017 in Los Angeles and New York"
#| echo: false
#| warning: false
#| message: false

number_of_cases_year_month <- 
  analysis_data_homicides |>
  # Group by solved and unsolved homicides and year
  group_by(arrest_was_not_made, year) |>
  # Count number of solved and unsolved homicides for each month per year 
  count(month)|>
  # Rename count column
  rename(
    "num_of_cases_month_year" = n
  ) |>
  mutate(
    month = case_when(
      (month == 1) ~ "Jan",
      (month == 2) ~ "Feb",
      (month == 3) ~ "Mar",
      (month == 4) ~ "Apr",
      (month == 5) ~ "May",
      (month == 6) ~ "Jun",
      (month == 7) ~ "Jul",
      (month == 8) ~ "Aug",
      (month == 9) ~ "Sep",
      (month == 10) ~ "Oct",
      (month == 11) ~ "Nov",
      (month == 12) ~ "Dec",
      TRUE ~ "None")
  ) |>
  mutate(
    arrest_was_not_made = case_when(
      (arrest_was_not_made == 1) ~ "Arrest was not made",
      (arrest_was_not_made == 0) ~ "Arrest was made",
      TRUE ~ "None")
  )

# To sort month in certain order 
# Referenced: https://www.geeksforgeeks.org/how-to-put-x-axis-in-order-month-in-r/ for code
number_of_cases_year_month$month <- factor(number_of_cases_year_month$month, levels = c('Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'))

# Referenced: https://stackoverflow.com/questions/12998372/heatmap-like-plot-but-for-categorical-variables to help create heatmap
number_of_cases_year_month |>
  ggplot(mapping = aes(x = month, y = year)) +
  geom_tile(aes(fill = num_of_cases_month_year)) + 
  # Creates two graphs based on the status of the case
  facet_wrap(facets = vars(arrest_was_not_made), dir = "v") +
  scale_fill_gradient(low = "#d8dac8", high = "#7f4f24", name = "Number of homicides") +
  theme_minimal() +
  labs(x = "Month", y = "Year") 
  # theme(legend.position = "bottom")
```

- TODO: Add in summary statistics table

### City 

```{r}
#| label: fig-city-bar
#| fig-cap: "Proportion of solved and unsolved homicides in Los Angeles and New York (2010 to 2017)"
#| echo: false
#| warning: false
#| message: false

number_of_cases_city <- 
  analysis_data_homicides |>
  # Group by city 
  group_by(city) |>
  # Count number of solved and unsolved homicides for each city
  count(arrest_was_not_made)|>
  # Rename count column
  rename(
    "num_of_cases_city" = n
  ) |>
  mutate(
    "proportion_of_cases" = round(num_of_cases_city/sum(num_of_cases_city), 2)
  ) |>
  mutate(
    arrest_was_not_made = case_when(
      (arrest_was_not_made == 1) ~ "Arrest was not made",
      (arrest_was_not_made == 0) ~ "Arrest was made",
      TRUE ~ "None")
  ) 

number_of_cases_city |>
  ggplot(mapping = aes(x = arrest_was_not_made, y = proportion_of_cases)) +
  # Creates two graphs based on the status of the case
  facet_wrap(facets = vars(city)) +
  geom_bar(stat = "identity", fill = "#a4ac86") +
  theme_minimal() +
  labs(x = "Status of the homicide case", y = "Proportion of cases") +
  theme(legend.position = "bottom")
```

```{r}
#| label: tbl-city-table
#| tbl-cap: "Proportion and number of solved and unsolved homicides in Los Angeles and New York (2010 to 2017)"
#| echo: false
#| warning: false
#| message: false

number_of_cases_city |>
  rename(
    "City" = city, 
    "Status of the homicide case" = arrest_was_not_made,
    "Proportion of cases" = proportion_of_cases,
    "Number of cases" = num_of_cases_city
  ) |>
  kable()
```

### Disposition
```{r}
#| label: fig-disposition-bar
#| fig-cap: "Disposition of homicide cases in New York and Los Angeles (2010 to 2017)"
#| echo: false
#| warning: false
#| message: false

number_of_dispositions_city <- 
  analysis_data_homicides |>
  # Group by city 
  group_by(city) |>
  # Count number of dispositions for each city
  count(disposition)|>
  # Rename count column
  rename(
    "num_of_disposition_city" = n
  )

number_of_dispositions_city |>
  ggplot(mapping = aes(x = disposition, y = num_of_disposition_city)) +
  # Creates two graphs based on the status of the case
  facet_wrap(facets = vars(city), dir = "v") +
  geom_bar(stat = "identity", fill = "#a4ac86") +
  theme_minimal() +
  labs(x = "Disposition of homicide", y = "Number of cases") +
  theme(legend.position = "bottom")
```

```{r}
#| label: tbl-disposition-table
#| tbl-cap: "Disposition of homicide cases in New York and Los Angeles (2010 to 2017)"
#| echo: false
#| warning: false
#| message: false

# Create table for dataframe pertaining to the number of cases per year
number_of_dispositions_city |>
  rename(
    "City" = city,
    "Disposition of the homicide case" = disposition,
    "Number of cases" = num_of_disposition_city
  ) |>
  kable()
```

\newpage

### Victim's Age 
```{r}
#| label: fig-victim-age-histogram
#| fig-cap: "Distribution of victim's age in solved and unsolved homicides in New York and Los Angeles (2010 to 2017)"
#| echo: false
#| warning: false
#| message: false

victim_age_dataframe <- 
  analysis_data_homicides |>
  # Group by age 
  group_by(victim_age) |>
  # Count number of solved and unsolved homicides by age
  count(arrest_was_not_made)|>
  # Rename count column
  rename(
    "num_of_cases" = n
  ) |>
  mutate(
    arrest_was_not_made = case_when(
      (arrest_was_not_made == 1) ~ "Arrest was not made",
      (arrest_was_not_made == 0) ~ "Arrest was made",
      TRUE ~ "None")
  ) 

# Referenced Telling Stories with Data by Rohan Alexander for histogram code: https://tellingstorieswithdata.com/05-graphs_tables_maps.html#histograms
victim_age_dataframe |>
  ggplot(aes(x = victim_age, fill = arrest_was_not_made)) +
  geom_histogram(position = "dodge") +
  theme_minimal() +
  scale_fill_manual(values=c("#936639", "#c2c5aa")) +
  labs(
    x = "Age of victim",
    y = "Number of cases",
    fill = "Status of homicide"
  ) +
  theme(legend.position = "bottom")
```

### Victim's Sex
```{r}
#| label: fig-victim-sex-bar
#| fig-cap: "Proportion of homicide cases per sex in New York and Los Angeles (2010 to 2017)"
#| echo: false
#| warning: false
#| message: false

number_of_cases_victim_sex <- 
  analysis_data_homicides |>
  # Group by victim's sex 
  group_by(victim_sex) |>
  # Count number of solved and unsolved homicides for each sex
  count(arrest_was_not_made)|>
  # Rename count column
  rename(
    "num_of_cases_victim_sex" = n
  ) |>
  mutate(
    "proportion_of_cases" = round(num_of_cases_victim_sex/sum(num_of_cases_victim_sex), 2)
  ) |>
  mutate(
    arrest_was_not_made = case_when(
      (arrest_was_not_made == 1) ~ "Arrest was not made",
      (arrest_was_not_made == 0) ~ "Arrest was made",
      TRUE ~ "None")
  ) 

number_of_cases_victim_sex |>
  ggplot(mapping = aes(x = victim_sex, y = proportion_of_cases)) +
  # Creates two graphs based on the status of the case
  facet_wrap(facets = vars(arrest_was_not_made)) +
  geom_bar(stat = "identity", fill = "#a4ac86") +
  theme_minimal() +
  labs(x = "Victim's Sex", y = "Proportion of cases") +
  theme(legend.position = "bottom")
```

```{r}
#| label: tbl-victim-sex-table
#| tbl-cap: "Proportion and number of homicide cases per sex in New York and Los Angeles (2010 to 2017)"
#| echo: false
#| warning: false
#| message: false

number_of_cases_victim_sex |>
  rename(
    "Victim's sex" = victim_sex, 
    "Status of the homicide case" = arrest_was_not_made,
    "Proportion of cases" = proportion_of_cases,
    "Number of cases" = num_of_cases_victim_sex
  ) |>
  kable()
```


### Victim's Race 
```{r}
#| label: fig-victim-race-bar
#| fig-cap: "Number of homicide cases per race in New York and Los Angeles (2010 to 2017)"
#| echo: false
#| warning: false
#| message: false

number_of_cases_victim_race <- 
  analysis_data_homicides |>
  # Group by victim's race 
  group_by(victim_race) |>
  # Count number of solved and unsolved homicides for each race
  count(arrest_was_not_made)|>
  # Rename count column
  rename(
    "num_of_cases_victim_race" = n
  ) |>
  mutate(
    arrest_was_not_made = case_when(
      (arrest_was_not_made == 1) ~ "Arrest was not made",
      (arrest_was_not_made == 0) ~ "Arrest was made",
      TRUE ~ "None")
  ) 

number_of_cases_victim_race |>
  ggplot(mapping = aes(x = victim_race, y = num_of_cases_victim_race)) +
  # Creates two graphs based on the status of the case
  facet_wrap(facets = vars(arrest_was_not_made)) +
  geom_bar(stat = "identity", fill = "#a4ac86") +
  theme_minimal() +
  labs(x = "Victim's Race", y = "Number of cases") +
  theme(legend.position = "bottom")
```

```{r}
#| label: tbl-victim-race-table
#| tbl-cap: "Number of homicide cases per sex in New York and Los Angeles (2010 to 2017)"
#| echo: false
#| warning: false
#| message: false

number_of_cases_victim_race |>
  rename(
    "Victim's race" = victim_race, 
    "Status of the homicide case" = arrest_was_not_made,
    "Number of cases" = num_of_cases_victim_race
  ) |>
  kable()
```

\newpage
## Model Results {#sec-model-results}
```{r}
#| label: tbl-model-result
#| tbl-cap: Relationship between a homicide being unsolved from 2010 to 2017 with the city and year a victim is found in/on and the race, age, and sex of a victim. Mean absolute deviation (MAD) values are in parenthesis.
#| echo: false
#| warning: false
#| message: false

modelsummary(
  # List out unsolved_model_results information
  list("Unsolved homicides (2010 to 2017)" = unsolved_model_results),
  # Specify MAD as the statistic
  statistic = "mad"
)
```



```{r}
#| label: fig-model-result-ci
#| fig-cap: The credible intervals (line) for coefficient estimates (dot) of predictor variables for homicides that go unsolved from 2010 to 2017.
#| echo: false
#| warning: false
#| message: false
# Specify credible interval to be 90% and present model results
modelplot(unsolved_model_results, conf_level = 0.9) +
  labs(x = "90 per cent credible interval")
```


\newpage
# Discussion {#sec-discussion}

## First discussion point {#sec-first-point}

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this. 

## Second discussion point

Please don't use these as sub-heading labels - change them to be what your point actually is.

## Third discussion point

## Areas of improvement and next steps

Weaknesses and next steps should also be included.

\newpage

\appendix

# Appendix {#sec-appendix}

## Note on Reproducing

In order to reproduce the results in the paper, first run the 00-install_packages.R in the scripts folder located in this paper’s GitHub repository. Then run the other scripts based on the number at the beginning of the script name.

## Acknowledgments

We would like to thank @citetellingstories for providing assistance with the R code used to produce the tables and graphs in this paper.

## Code styling

Code written in the scripts was checked and styled with lintr [@citelintr] and styler [@citestyler].

## Additional Tables

```{r}
#| label: tbl-month-table
#| tbl-cap: "Number of solved and unsolved homicides across the 12 months of a year in Los Angeles and New York (2010 to 2017)"
#| echo: false
#| warning: false
#| message: false

# Create table for the number of cases per month
number_of_cases_month |>
  rename(
    "Month" = month,
    "Status of the homicide case" = arrest_was_not_made,
    "Number of cases in the month" = num_of_cases_month
  ) |>
  kable()
```


```{r}
#| label: tbl-year-table
#| tbl-cap: "Number of solved and unsolved homicides from 2010 to 2017 in Los Angeles and New York"
#| echo: false
#| warning: false
#| message: false

# Create table for dataframe pertaining to the number of cases per year
number_of_cases_year |>
  rename(
    "Year" = year,
    "Status of the homicide case" = arrest_was_not_made,
    "Number of cases in the year" = num_of_cases_year
  ) |>
  kable()
```

\newpage
## Idealized Survey and Methodology {#sec-ideal-survey}
- Link to literature

### Idealized Survey Objectives

### Sampling Approach
- what is the population, frame, and sample;
- how is the sample recruited;
- what sampling approach is taken, and what are some of the trade-offs of this; 
- how is non-response handled;


### Respondent Recruitment

### Data Validation

### Idealized Survey Design

### Link to Idealized Survey
- Using Google Forms

### Limitations
- what is good and bad about the sampling.

### Idealized Survey Questions
- Should have an introductory section and include details of a contact person
- Question type should be varied and appropriate.
- Have a final section that thank the respondents


\newpage 

## Model details {#sec-model-details}

### Variance Inflation Factor

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: tbl-vif
#| tbl-cap: "Valence inflation factor (VIF) of each predictor for unsolved homicide model from 2010 to 2017"

# Referenced: https://www.bookdown.org/rwnahhas/RMPH/mlr-collinearity.html
vif(unsolved_model_results) |>
  kable()
```


### Posterior predictive check

In @fig-ppcheckandposteriorvsprior-1 we implement a posterior predictive check. This shows...

In @fig-ppcheckandposteriorvsprior-2 we compare the posterior with the prior. This shows... 

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-ppcheckandposteriorvsprior
#| layout-ncol: 2
#| fig-cap: "Examining how the model fits, and is affected by, the data"
#| fig-subcap: ["Posterior prediction check", "Comparing the posterior with the prior"]

pp_check(unsolved_model_results) +
  theme_classic() +
  theme(legend.position = "bottom")

posterior_vs_prior(unsolved_model_results) +
  theme_minimal() +
  scale_color_brewer(palette = "Set1") +
  theme(legend.position = "bottom") +
  coord_flip()
```


### Diagnostics

@fig-stanareyouokay-1 is a trace plot. It shows... This suggests...

@fig-stanareyouokay-2 is a Rhat plot. It shows... This suggests...


```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-stanareyouokay
#| fig-cap: "Checking the convergence of the MCMC algorithm"
#| fig-subcap: ["Trace plot", "Rhat plot"]
#| layout-ncol: 2

plot(unsolved_model_results, "trace")

plot(unsolved_model_results, "rhat")
```


\newpage


# References


