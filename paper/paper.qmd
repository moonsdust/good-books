---
title: "Differences in Homicide Case Information Indicates Why Justice is Not Served"
subtitle: "An analysis of solved and unsolved homicides from 2010 to 2017 in one of the United States' 2 largest cities, Chicago and Los Angeles"
author: 
  - Emily Su
thanks: "Code and data are available at: [https://github.com/moonsdust/unsolved-murders](https://github.com/moonsdust/unsolved-murders)."
date: today
date-format: long
abstract: "Despite Chicago Mayor Brandon Johnson announcing in 2024 that the Chicago Police Department had the highest homicide clearance rate of 54% in years, homicide clearance rates across the United States (US) have been decreasing since 1980, with more homicides going unsolved. This paper looks at patterns of homicide case information with the case resolution from 2010 to 2017 in two of the largest cities in the United States, Chicago and Los Angeles. We found that unsolved homicides are more likely to occur in Chicago compared to Los Angeles, and the majority of unsolved homicide victims are Black or Hispanic and are male. These findings can inform the public and US police departments of populations more vulnerable to having unsolved cases however further investigation is needed on the investigators involved in each unsolved homicide case."
format:
  pdf:
    toc: true
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(arrow)
library(ggplot2)
library(modelsummary)
library(rstanarm)
library(dplyr)
library(knitr)
library(car)
library(DiagrammeR)
library(rsvg)
library(DiagrammeRsvg)
library(png)

# Read in analysis data
analysis_data_homicides <- read_parquet("../data/02-analysis_data/cleaned_data_homicides.parquet")
# Read in model data
unsolved_model_results <- readRDS("../models/unsolved_homicide_model.rds")
```


# Introduction

On November 20, 2024, Chicago Mayor Brandon Johnson announced that the Chicago Police Department had the highest homicide clearance rate of 54% in recent years [@citechicagonews]. Despite celebrating this accomplishment, @citechicagonews found that if only the cases with arrest were considered and not closed cases where the police believed they had identified the perpetrator without an arrest being made, their clearance rate was instead 23% this year. This concern about homicide clearance rate was expressed by @citeguardian, who mentioned that homicide clearance rates from 1980 to 2020 have decreased from 71% to 50% in the United States (US). As of 2023, there are currently no up-to-date databases keeping track of homicide resolutions, and current crime databases do not indicate a victim's race and what led to a homicide, making it difficult to figure out why homicides are going unsolved [@citeguardian]. The ongoing concern about homicide clearance raises the following question: what are the differences in homicide case information like the year and city where the homicide took place and the victim's perceived characteristics (age, sex, and race) between solved and unsolved homicides in the 2 of the largest cities in the United States, Chicago and Los Angeles, from 2010 to 2017?

Our estimand is the homicide case information like the victim's demographic information (age, sex, and race) and the year and city the homicide occurred in/on if the homicide case is unsolved or solved. 

In this paper, to see what factors could impact the likelihood of a homicide case going unsolved, we analyzed data provided by The Washington Post [@datahomicides] that was compiled by their reporters on homicide cases and their status from 2010 to 2017. Previously, The Washington Post used the data they assembled to construct a map and pinpoint places where unsolved homicides occur [@citewashingtonpostmap]. In another study, @citeIndiana looked at factors that contributed to the low homicide clearance rates in Indianapolis, Indiana across different neighbourhoods. They found that there was an association between neighbourhoods with higher arrest rates and having a higher chance of homicide clearance [@citeIndiana]. However, specific analysis looking at the differences in case characteristics between two US cities, Chicago and Los Angeles, has not been done previously. Our findings indicate that a majority of unsolved homicide victims from 2010 to 2017 are Black or Hispanic and are likely to be male but their age does not impact if their case goes unsolved or not. We also found that unsolved homicides are more likely to occur in Chicago compared to Los Angeles from 2010 to 2017. From our analysis, most unsolved homicide cases occurred during the middle and later half of the year with there being a jump in unsolved cases from 2016 onwards. These findings could inform the public and police departments about populations more vulnerable to homicide cases going unsolved and cities to be more alert about such as Chicago with homicide clearance rates. 

For the remainder of the paper, the data section (@sec-data) goes over the data we used and its features and limitations, how the data was obtained, our variables of interest for our model and preliminary analysis, and a bit of our data cleaning process. The model section (@sec-model) discusses the type of model we used, the relationships between variables in our model, the justification for our model including the root mean square error (RMSE) for our model. The results section (@sec-results) contains tables and graphs created based on our data and the results from our model. The discussion section (@sec-discussion) goes over what we did in our results, explaining the meaning of our findings, the implications of our findings to the real world, and areas of improvement and suggestions for future works. The appendix (@sec-appendix) includes a link to a dashboard that was created with interactive versions of the graphs in this paper, additional tables, notes on reproducing and code styling, model diagnostics and validation, our idealized survey and methodology to gather data on investigators responsible for homicide cases, and our evaluation of The Washington Post's methodology. 

# Data {#sec-data}

## Overview

The dataset we used for this paper comes from The Washington's Post's GitHub repository, "How The Post mapped unsolved murders", which is also known as the "Unsolved Homicide Database" [@datahomicides]. We used the statistical programming language R [@citeR], tidyverse [@citetidyverse], janitor [@citejanitor], lubridate [@citelubridate], dplyr [@citedplyr], ggplot2 [@citeggplot2], arrow [@citearrow], testthat [@citetestthat], and knitr [@citeknitr] to retrieve, clean, test, and analyze the dataset. To construct, test, and analyze our model, we used the following packages: rstanarm [@citerstanarm], modelsummary [@citemodelsummary], and car [@citecar]. The causal model diagram created to understand the relationship between predictor variables, the outcome variable, and a confounder used DiagrammeR [@citeDiagrammeR], rsvg [@citersvg], DiagrammeRsvg [@citeDiagrammeRsvg] and png [@citepng].

The Washington Post's Unsolved Homicide Database is a dataset compiled by Washington Post reporters that contains over 52000 homicides in the United States (US) from 50 of the largest US cities from 2007 to 2017 [@datahomicides]. This dataset includes information about the victim such as their name, sex, race, and age as well as geographic and temporal information of the homicide. The Washington Post was interested in using the information compiled to map unsolved homicides across the United States in major cities from 2007 to 2017 [@citewashingtonpostmap]. Another dataset we had considered using was another one compiled by The Washington Post on school shootings across the US and approaching our problem with a different perspective on the characteristics of the perpetrator. However, due to there only being 416 observations and numerous observations missing information, we forgo using the dataset. 

The raw dataset we retrieved from The Washington Post using a script that downloads the CSV file from their GitHub repository contains 52,179 observations with each observation being a homicide case. However, since we narrowed our scope to focus on the two of the most populated US cities, Los Angeles and Chicago, the number of observations in our cleaned dataset ended up being 6,307. Our data look as follows: 

```{r}
#| label: tbl-dataset-preview
#| tbl-cap: Preview of dataset on solved and unsolved homicides (2010 to 2017) with the original dataset compiled by The Washington Post 
#| echo: false
#| warning: false
#| message: false

# Create table to display dataset
analysis_data_homicides |>
  head() |>
  kable()
```

```{r}
#| label: tbl-dataset-statistics
#| tbl-cap: Number of observations, minimum, maximum, median, mean, 1st and 3rd quartile of variables in dataset on solved and unsolved homicides (2010 to 2017) excluding victim_sex, city, and disposition
#| echo: false
#| warning: false
#| message: false

# Create table to display summary statistics
analysis_data_homicides |>
  select(-c(city, victim_sex, disposition)) |>
  summary() |>
  kable()
```

@tbl-dataset-preview and @tbl-dataset-statistics indicates our variables of interest, which are the following: victim_race, victim_age, victim_sex, city, disposition, year, month, and arrest_was_not_made. victim_race represents the race of the homicide victim, which can be "White" (376 observations), "Hispanic" (1,763 observations), "Black" (4,063 observations), "Asian" (43 observations), and "Other" (62 observations). victim_age signifies the age of the homicide victim at the time of their death and is defined as a whole number. @tbl-dataset-statistics shows that the mean victim_sex is the sex of the homicide victim where they are either identified as a "female" or "male". The city variable defines the city the victim is reported to have been found in. The disposition variable is the specific status of a homicide case where a case can fall in either of the following three status: "Closed by arrest", "Open/No arrest", and "Closed without arrest". The year variable represents a year from 2010 to 2017 that indicates the year the homicide took place. Following this, the month variable represents the month a homicide took place. arrest_was_not_made is a variable that was constructed based on the disposition variable with "Closed by arrest" being converted to a 0 and "Open/No arrest" and "Closed without arrest" being converted to a 1. arrest_was_not_made indicates the status of a homicide case as either being unsolved, which is denoted by a 1, and solved, which is denoted by a 0. 

However, our dataset has limitations. There was only data available from 2010 onwards for Los Angeles provided by The Washington Post and so that limited the number of homicides we could look at for both Chicago and Los Angeles. Also, not all victims were able to be identified in some homicide cases and unknown attributes of the victim such as their age, sex, and gender were indicated with the text "Unknown" in the dataset. However, this causes issues with data type compatibility such as the value "Unknown" being a character type being under the victim_age column, which has a data type of integer. This would lead to issues with our model providing accurate estimates. We decided to remove cases during our data cleaning where victim's demographic information is missing at least one of the three columns, victim_age, victim_sex, victim_race. 

## Measurement

The Federal Bureau of Investigation (FBI) has a program called the Uniform Crime Reporting (UCR) Program to generate statistics for the public [@citeFBIinfo]. The FBI originally had a system under the UCR called Summary Reporting System (SRS), which obtained details about different crimes taking place from law enforcement agencies nationwide such as victim information [@citeFBIinfo]. However, the SRS was replaced with a new system called the National Incident-Based Reporting System (NIBR) in 2021 that obtained more details about various crimes [@citeFBIinfo]. For The Los Angeles Police Department, after a homicide case occurs, the investigating team handwrites information into physical crime reports with details like the type of crime, the premise the crime occured at, and the age and ethnicity of the victim [@citeLApolice]. The crime reports are then transcribed into a digital format and then sent to the SRS monthly [@citeLApolice]. After a homicide occurs in Chicago, The Chicago Police Department uses a system called the Chicago Police Department's CLEAR (Citizen Law Enforcement Analysis and Reporting) system to report on details such as the victim, if an arrest was made or not, and the location the crime took [@citeChicagoPolice]. This information is then reported to the FBI monthly under the UCR program [@citeChicagoPolice]. 

Reporters from the Washington Post then obtained the data from the FBI specifically on homicides from 50 largest US cities from 2007 to 2017, which can be access through the UCR publications page on the FBI website [@datahomicides]. They selected the 50 largest cities based the size of the city in 2012 [@datahomicides]. They also obtain data about homicide counts and closure rates through papers and compare these values with the ones from the FBI dataset for accuracy [@datahomicides]. The Washington Post would also use public records like medical examiner reports, death certificates, and court records, to fill in any missing information since some departments only report partial information to the FBI [@datahomicides]. The Washington Post defined cases to be closed without arrest when they are reported by the police as "exceptionally cleared" where there is evidence of who the perpetrator is but an arrest is not possible because of reason like they has died [@datahomicides]. They also define cases to be closed by arrest if the police reported it to be and other cases are defined to be open/no arrest [@datahomicides].

## Outcome variable
The outcome variable we are interested in looking at with our model and our analysis is the arrest_was_not_made variable. We use this variable to compare homicide case characteristics of solved and unsolved homicides.  

## Predictor variables
The predictor variables for our model are the following: victim_race, victim_age, victim_sex, city, and year. The variables, disposition and month are not predictor variables in our model but they are used to investigate trends between homicide case information and the status of the homicide being solved or unsolved. 

\newpage

# Model {#sec-model}
The model we implemented was a Bayesian logistic regression model. This model was constructed after we saw patterns between homicide case information and a homicide case going unsolved in our analysis. We are interested in seeing if certain characteristics of a homicide case such as the victim's perceived characteristics (sex, gender, age) and the year and city the victim is found impacts the likelihood of their case going unsolved. 

## Model set-up
With our model, we will make the assumption that there is a relationship between homicide case information like the victim's race, victim's age, victim's sex, the city, and the year with a homicide case being unsolved. We also assume that the predictor variables are independent from one another, which we check in @sec-model-details using variance inflation factor (VIF) and it indicates the predictors are not highly correlated with each other. We define our model as follows:
\begin{align*}
y_i|\pi_i &\sim \mbox{Bern}(\pi_i) \\
\mbox{logit}(\pi_i) &= \beta_0 + \beta_1 \times \mbox{victim\_race}_i + \beta_2 \times \mbox{victim\_age}_i + \beta_3 \times \mbox{victim\_sex}_i + \beta_4 \times \mbox{city}_i + \beta_5 \times \mbox{year}_i\\
\beta_0 &\sim \mbox{Normal}(0, 2.5) \\
\beta_1 &\sim \mbox{Normal}(0, 2.5) \\
\beta_2 &\sim \mbox{Normal}(0, 2.5) \\
\beta_3 &\sim \mbox{Normal}(0, 2.5) \\
\beta_4 &\sim \mbox{Normal}(0, 2.5) \\
\beta_5 &\sim \mbox{Normal}(0, 2.5)
\end{align*}

We define $y_i$ to be the status of the homicide case where 1 means the homicide is unsolved (case is still open / been closed without arrest) and 0 means the homicide is solved (case has been closed with arrest). $\pi_i$ represents the probability of the homicide being solved. $\mbox{logit}(\pi_i)$ indicates the log-odds of the homicide being unsolved. Now looking at the coefficients $b_i$ and predictor variables, $\beta_0$ is the intercept of our model and is the log-odds when all predictor variables are equal to 0. $\mbox{victim\_race}_i$ signifies the race of the victim, which could be either "Asian", "Black", "Hispanic", "White", and "Other". In our model, we use "White" as the baseline for $\mbox{victim\_race}_i$ to see if being part of a minority impacts if the case goes unsolved or not. $\beta_1$ is the coefficient that represents the log-odds when $\mbox{victim\_race}_i$ changes. $\mbox{victim\_age}_i$ is the victim's age, which is a whole number. $\beta_2$ is the log-odds when $\mbox{victim\_age}_i$ increases by 1 year. $\mbox{victim\_sex}_i$ represents the sex of the victim, where in the dataset it is either "female" or "male" and $\beta_3$ is the log-odds when $\mbox{victim\_sex}_i$ changes. $\mbox{city}_i$ is the city the victim was reported to be killed in, which from our dataset could be either "Chicago" or "Los Angeles". $\beta_4$ is the coefficient that stands for the log-odds when $\mbox{city}_i$ changes. We define $\mbox{year}_i$ to be the year the homicide was reported to have occured from 2010 to 2017. $\beta_5$ indicates the log-odds when $\mbox{year}_i$ increases by 1 year.

Our model runs in R [@citeR] using the rstanarm package [@citerstanarm]. For our model's priors, we use the default priors provided by rstanarm [@citerstanarm]. Diagnostics for the model such as in posterior predictive check, trace and Rhat plots can be found in @sec-model-details.

## Model justification

In our model, we assumed there is a relationship between the outcome variable, homicide is unsolved, with homicide case information like demographic (sex, race, and age of victim), geographic (city), and temporal (year) information, which are the predictor variables. For the demographic data, we decided to keep the grouping provided by The Washington Post such as for sex it was "female" and "male" and race it was "White", "Black", "Hispanic", "Asian", and "Other. However, we did remove victims who has any demographic information that falls under the "Unknown" grouping from our dataset and did not run our regression model on these observations. The reason for this is due to factors such as the data type of the predictor and keeping consistency across all observation and removing any unknown values. For example, our predictor variable, victim's age is a integer data type but it contained the string "Unknown" in the raw dataset. So the values "Unknown" is removed in our final dataset and not used to train our model. Since our outcome variable is binary for our model, we constructed the arrest_was_not_made column for it based on the disposition variable to reflect it and considered dispositions with values like "Open/No arrest" and "Closed without arrest" to be 1 and "Closed by arrest" to be 0.

We used a logistic regression model in a Bayesian framework due to the fact that our outcome is binary and predicts if a homicide is unsolved or not. Another model we considered is a logistic regression model with an instrumental variable. Introducing a instrumental variable into our model could have potentially provided a more accurate model and given us more consistent coefficient estimates as noted by @citeucdavis. However with the available information we had about each case, there was no candidate instrumental variable that impacted at least one variable in our data and not influence the outcome of the case being solved or unsolved. Thus, the model would fail the "Exclusion Restriction" assumption mentioned by @citetellingstories. We also went through different pairs and groupings of variables and how there was not a strong relationship between variables that is relevant and consequently fail @citetellingstories's "Relevance" assumption. We also have known treatment variable/predictor variables that can be used to measure the outcome variable and therefore, the instrumental variable is less likely to be necessary [@citetellingstories].

Performing root mean square error (RSME) calculations on our model in @tbl-model-result yields a RSME value of about 0.45. RSME represents the difference between the model's predicted values and observed values with 0 meaning that the predicted and observed values are the same [@citejim]. Since the model's RSME value is close to 0, we can say our model is able to predict values with less error compared to other models that have a higher RSME value. 

```{r}
#| label: fig-causal-model
#| fig-cap: Causal relationship between homicide case information and homicide case being unsolved 
#| echo: false
#| warning: false
#| message: false

# Referenced code from: https://stackoverflow.com/questions/42737645/how-to-export-images-of-diagrammer-in-r and https://www.erikigelstrom.com/articles/causal-graphs-in-r-with-diagrammer/
causal_model <- "digraph { graph []
  # Nodes
  node [shape = plaintext]
    A [label = 'Case being unsolved']
    B [label = 'Race of victim']
    C [label = 'Age of victim']
    D [label = 'Sex of victim']
    E [label = 'City']
    F [label = 'Date (Year)']
    G [label = 'Resources of investigating team (Confounder)']
  edge []
    B->A
    C->A
    D->A
    E->A
    F->A
{ rank = same; }
  # Confounding variables's edges 
  edge [style = dashed]
    G -> A
    G -> E
    G -> F
}"
# Export diagram as a png
exporting_image <- grViz(causal_model) |>
  export_svg() |>
  charToRaw() |>
  rsvg_png("../other/sketches/casual_model.png", width = 1000)

# NOTE: Needed to save diagram and read it in as an image since grViz doesn't render in PDFs
# Referenced https://stackoverflow.com/questions/23861000/displaying-images-in-r-in-version-3-1-0
the_image <- readPNG("../other/sketches/casual_model.png")
plot.new()
rasterImage(the_image, 0,0,1.05,1)
```

However, our model has limitations and there are situations where this model would not work. @fig-causal-model shows that there is a confounder, "resources of investigating team" between the predictor variables, city and year and the outcome variable, case being unsolved. We define "resources of the investigating team" to include any of the following: the amount of people on the team investigating the case, time available allotted to investigate the case, amount of open cases for the team, cost, skill and education levels of members, etc. We currently do not have any information available about the resources of the investigating team for the case and further investigation is needed. We proposed an idealized survey we would conduct to collect the necessary data to further understand the relationship between homicide case characteristics and unsolved homicides in @sec-ideal-survey. If we have information available about the resources of the investigating team for the case, the current model would not work and would need to be revised. This is due to the interaction between the city, year, and outcome variables with the confounder.  

\newpage

# Results {#sec-results}

## Differences in Homicide Case Information Between Solved and Unsolved Cases in Chicago and Los Angeles (2010 to 2017)

### Date (Month and Year)
```{r}
#| label: fig-month-bar
#| fig-cap: "Number of solved and unsolved homicides across the 12 months of a year in Los Angeles and Chicago (2010 to 2017)"
#| echo: false
#| warning: false
#| message: false

number_of_cases_month <- 
  analysis_data_homicides |>
  # Group by solved and unsolved homicides 
  group_by(arrest_was_not_made) |>
  # Count number of solved and unsolved homicides for each month
  count(month)|>
  # Rename count column
  rename(
    "num_of_cases_month" = n
  ) |>
  mutate(
    month = case_when(
      (month == 1) ~ "Jan",
      (month == 2) ~ "Feb",
      (month == 3) ~ "Mar",
      (month == 4) ~ "Apr",
      (month == 5) ~ "May",
      (month == 6) ~ "Jun",
      (month == 7) ~ "Jul",
      (month == 8) ~ "Aug",
      (month == 9) ~ "Sep",
      (month == 10) ~ "Oct",
      (month == 11) ~ "Nov",
      (month == 12) ~ "Dec",
      TRUE ~ "None")
  ) |>
  mutate(
    arrest_was_not_made = case_when(
      (arrest_was_not_made == 1) ~ "Arrest was not made",
      (arrest_was_not_made == 0) ~ "Arrest was made",
      TRUE ~ "None")
  )

# To sort month in certain order 
# Referenced: https://www.geeksforgeeks.org/how-to-put-x-axis-in-order-month-in-r/ for code
number_of_cases_month$month <- factor(number_of_cases_month$month, levels = c('Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'))

number_of_cases_month |>
  ggplot(mapping = aes(x = month, y = num_of_cases_month)) +
  # Creates two graphs based on the status of the case
  facet_wrap(facets = vars(arrest_was_not_made), dir = "v") +
  geom_bar(stat = "identity", fill = "#a4ac86") +
  theme_minimal() +
  labs(x = "Month of the year", y = "Number of homicide cases") +
  theme(legend.position = "bottom")
```
@fig-month-bar and @tbl-month-table indicates that most of the unsolved homicide cases in Los Angeles and Chicago from 2010 to 2017 were reported in the summer months with there being 436 unsolved cases in July and 440 for August. @fig-month-bar shows that most unsolved homicide cases occur during the middle and later half of the year. On the other hand,  @tbl-month-table and @fig-month-bar shows that the number of cases that were reported with arrest also happen during August with 203 cases and June with 201 cases. However, there also are fewer arrest made compared to the number of cases where an arrest was not made.

```{r}
#| label: fig-year-bar
#| fig-cap: "Number of solved and unsolved homicides from 2010 to 2017 in Los Angeles and Chicago"
#| echo: false
#| warning: false
#| message: false

number_of_cases_year <- 
  analysis_data_homicides |>
  # Group by solved and unsolved homicides 
  group_by(arrest_was_not_made) |>
  # Count number of solved and unsolved homicides for each year
  count(year)|>
  # Rename count column
  rename(
    "num_of_cases_year" = n
  ) |>
  mutate(
    arrest_was_not_made = case_when(
      (arrest_was_not_made == 1) ~ "Arrest was not made",
      (arrest_was_not_made == 0) ~ "Arrest was made",
      TRUE ~ "None")
  )

number_of_cases_year |>
  ggplot(mapping = aes(x = as.character(year), y = num_of_cases_year)) +
  # Creates two graphs based on the status of the case
  facet_wrap(facets = vars(arrest_was_not_made), dir = "v") +
  geom_bar(stat = "identity", fill = "#a4ac86") +
  theme_minimal() +
  labs(x = "Year", y = "Number of homicide cases") +
  theme(legend.position = "bottom")
```
@fig-year-bar and @tbl-year-table shows that there was sudden increase in the number of unsolved homicides reported in 2016 and 2017 compared to previous years with 775 cases for 2016 and 746 cases for 2017. However, for the cases with an arrest made, most of the cases were reported back in 2012 with 290 cases and 2016 and 279 cases.

```{r}
#| label: fig-year-month-heatmap
#| fig-cap: "Number of solved and unsolved homicides from January to December from 2010 to 2017 in Los Angeles and Chicago"
#| echo: false
#| warning: false
#| message: false

number_of_cases_year_month <- 
  analysis_data_homicides |>
  # Group by solved and unsolved homicides and year
  group_by(arrest_was_not_made, year) |>
  # Count number of solved and unsolved homicides for each month per year 
  count(month)|>
  # Rename count column
  rename(
    "num_of_cases_month_year" = n
  ) |>
  mutate(
    month = case_when(
      (month == 1) ~ "Jan",
      (month == 2) ~ "Feb",
      (month == 3) ~ "Mar",
      (month == 4) ~ "Apr",
      (month == 5) ~ "May",
      (month == 6) ~ "Jun",
      (month == 7) ~ "Jul",
      (month == 8) ~ "Aug",
      (month == 9) ~ "Sep",
      (month == 10) ~ "Oct",
      (month == 11) ~ "Nov",
      (month == 12) ~ "Dec",
      TRUE ~ "None")
  ) |>
  mutate(
    arrest_was_not_made = case_when(
      (arrest_was_not_made == 1) ~ "Arrest was not made",
      (arrest_was_not_made == 0) ~ "Arrest was made",
      TRUE ~ "None")
  )

# To sort month in certain order 
# Referenced: https://www.geeksforgeeks.org/how-to-put-x-axis-in-order-month-in-r/ for code
number_of_cases_year_month$month <- factor(number_of_cases_year_month$month, levels = c('Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'))

# Referenced: https://stackoverflow.com/questions/12998372/heatmap-like-plot-but-for-categorical-variables to help create heatmap
number_of_cases_year_month |>
  ggplot(mapping = aes(x = month, y = year)) +
  geom_tile(aes(fill = num_of_cases_month_year)) + 
  # Creates two graphs based on the status of the case
  facet_wrap(facets = vars(arrest_was_not_made), dir = "v") +
  scale_fill_gradient(low = "#d8dac8", high = "#7f4f24", name = "Number of homicides") +
  theme_minimal() +
  labs(x = "Month", y = "Year") 
  # theme(legend.position = "bottom")
```
Based on where the dark brown colour appears in @fig-year-month-heatmap, majority of homicides that go unsolved occur in the middle and later half of 2016 while for 2017 most of them happen middle of 2017. For the homicides that go solved, the lightness appears to be uniform across with the more dark parts in the middle of @fig-year-month-heatmap. 


\newpage
### City 

```{r}
#| label: fig-city-bar
#| fig-cap: "Proportion of solved and unsolved homicides in Los Angeles and Chicago (2010 to 2017)"
#| echo: false
#| warning: false
#| message: false

number_of_cases_city <- 
  analysis_data_homicides |>
  # Group by city 
  group_by(city) |>
  # Count number of solved and unsolved homicides for each city
  count(arrest_was_not_made)|>
  # Rename count column
  rename(
    "num_of_cases_city" = n
  ) |>
  mutate(
    "proportion_of_cases" = round(num_of_cases_city/sum(num_of_cases_city), 2)
  ) |>
  mutate(
    arrest_was_not_made = case_when(
      (arrest_was_not_made == 1) ~ "Arrest was not made",
      (arrest_was_not_made == 0) ~ "Arrest was made",
      TRUE ~ "None")
  ) 

number_of_cases_city |>
  ggplot(mapping = aes(x = arrest_was_not_made, y = proportion_of_cases)) +
  # Creates two graphs based on the status of the case
  facet_wrap(facets = vars(city)) +
  geom_bar(stat = "identity", fill = "#a4ac86") +
  theme_minimal() +
  labs(x = "Status of the homicide case", y = "Proportion of cases") +
  theme(legend.position = "bottom")
```

```{r}
#| label: tbl-city-table
#| tbl-cap: "Proportion and number of solved and unsolved homicides in Los Angeles and Chicago (2010 to 2017)"
#| echo: false
#| warning: false
#| message: false

number_of_cases_city |>
  rename(
    "City" = city, 
    "Status of the homicide case" = arrest_was_not_made,
    "Proportion of cases" = proportion_of_cases,
    "Number of cases" = num_of_cases_city
  ) |>
  kable()
```

@fig-city-bar and @tbl-city-table shows that 77% of Chicago's homicide cases are unsolved (with 3,164 cases) while for Los Angeles, 49% (1,087 cases) of their homicide cases are unsolved from 2010 to 2017. Only 23% (947 cases) of homicide cases are solved with an arrest made for Chicago while for Los Angeles, 51% (1,109 cases) of homicides are solved with an arrest made. Chicago has a higher percentage and higher number of unsolved homicide cases compared to Los Angeles. 


\newpage

### Disposition
```{r}
#| label: fig-disposition-bar
#| fig-cap: "Disposition of homicide cases in Chicago and Los Angeles (2010 to 2017)"
#| echo: false
#| warning: false
#| message: false

number_of_dispositions_city <- 
  analysis_data_homicides |>
  # Group by city 
  group_by(city) |>
  # Count number of dispositions for each city
  count(disposition)|>
  # Rename count column
  rename(
    "num_of_disposition_city" = n
  )

number_of_dispositions_city |>
  ggplot(mapping = aes(x = disposition, y = num_of_disposition_city)) +
  # Creates two graphs based on the status of the case
  facet_wrap(facets = vars(city), dir = "v") +
  geom_bar(stat = "identity", fill = "#a4ac86") +
  theme_minimal() +
  labs(x = "Disposition of homicide", y = "Number of cases") +
  theme(legend.position = "bottom")
```

```{r}
#| label: tbl-disposition-table
#| tbl-cap: "Disposition of homicide cases in Chicago and Los Angeles (2010 to 2017)"
#| echo: false
#| warning: false
#| message: false

# Create table for dataframe pertaining to the number of cases per year
number_of_dispositions_city |>
  rename(
    "City" = city,
    "Disposition of the homicide case" = disposition,
    "Number of cases" = num_of_disposition_city
  ) |>
  kable()
```

@fig-disposition-bar and @tbl-disposition-table shows that the number of homicide cases that are closed by arrest at 1,109 cases is close to the number of homicide cases that are open at 1,087 cases from 2010 to 2017. On the hand, there is a larger gap for Chicago between the number of homicides that are closed by arrest at 947 cases with the ones that are closed without arrest and open/no arrest at 216 and 2,948 cases, respectively. 

\newpage

### Victim's Age 
```{r}
#| label: fig-victim-age-histogram
#| fig-cap: "Distribution of victim's age in solved and unsolved homicides in Chicago and Los Angeles (2010 to 2017)"
#| echo: false
#| warning: false
#| message: false

victim_age_dataframe <- 
  analysis_data_homicides |>
  # Group by age 
  group_by(victim_age) |>
  # Count number of solved and unsolved homicides by age
  count(arrest_was_not_made)|>
  # Rename count column
  rename(
    "num_of_cases" = n
  ) |>
  mutate(
    arrest_was_not_made = case_when(
      (arrest_was_not_made == 1) ~ "Arrest was not made",
      (arrest_was_not_made == 0) ~ "Arrest was made",
      TRUE ~ "None")
  ) 

# Referenced Telling Stories with Data by Rohan Alexander for histogram code: https://tellingstorieswithdata.com/05-graphs_tables_maps.html#histograms
victim_age_dataframe |>
  ggplot(aes(x = victim_age, fill = arrest_was_not_made)) +
  geom_histogram(position = "dodge") +
  theme_minimal() +
  scale_fill_manual(values=c("#936639", "#c2c5aa")) +
  labs(
    x = "Age of victim",
    y = "Number of cases",
    fill = "Status of homicide"
  ) +
  theme(legend.position = "bottom")
```

```{r}
#| label: tbl-victim-age-statistics
#| tbl-cap: Minimum, maximum, median, mean, 1st and 3rd quartile of variables in dataset on solved and unsolved homicides (2010 to 2017) excluding victim_sex, city, and disposition
#| echo: false
#| warning: false
#| message: false

# Create table to display summary statistics
victim_age_dataframe |>
  select(-c(arrest_was_not_made, num_of_cases)) |>
  rename(
    "Victim's Age" = victim_age
  ) |>
  summary() |>
  kable()
```

@fig-victim-age-histogram shows that the distribution of age of homicide victims is relatively uniform. It appears that the victims of unsolved and solved homicides are about the same age if one were not to consider ages above 75. However, if we were to consider age 75 onwards, it appears that the distribution is a bit right-skewed. We can see that from @tbl-victim-age-statistics, the youngest homicide victim is 1 years old and the oldest is 94 years old. The median age of homicide victims is 44 years old with the mean age being 45 years old. 

### Victim's Sex
```{r}
#| label: fig-victim-sex-bar
#| fig-cap: "Proportion of homicide cases per sex in Chicago and Los Angeles (2010 to 2017)"
#| echo: false
#| warning: false
#| message: false

number_of_cases_victim_sex <- 
  analysis_data_homicides |>
  # Group by victim's sex 
  group_by(victim_sex) |>
  # Count number of solved and unsolved homicides for each sex
  count(arrest_was_not_made)|>
  # Rename count column
  rename(
    "num_of_cases_victim_sex" = n
  ) |>
  mutate(
    "proportion_of_cases" = round(num_of_cases_victim_sex/sum(num_of_cases_victim_sex), 2)
  ) |>
  mutate(
    arrest_was_not_made = case_when(
      (arrest_was_not_made == 1) ~ "Arrest was not made",
      (arrest_was_not_made == 0) ~ "Arrest was made",
      TRUE ~ "None")
  ) 

number_of_cases_victim_sex |>
  ggplot(mapping = aes(x = victim_sex, y = proportion_of_cases)) +
  # Creates two graphs based on the status of the case
  facet_wrap(facets = vars(arrest_was_not_made)) +
  geom_bar(stat = "identity", fill = "#a4ac86") +
  theme_minimal() +
  labs(x = "Victim's Sex", y = "Proportion of cases") +
  theme(legend.position = "bottom")
```

```{r}
#| label: tbl-victim-sex-table
#| tbl-cap: "Proportion and number of homicide cases per sex in Chicago and Los Angeles (2010 to 2017)"
#| echo: false
#| warning: false
#| message: false

number_of_cases_victim_sex |>
  rename(
    "Victim's sex" = victim_sex, 
    "Status of the homicide case" = arrest_was_not_made,
    "Proportion of cases" = proportion_of_cases,
    "Number of cases" = num_of_cases_victim_sex
  ) |>
  kable()
```

@fig-victim-sex-bar and @tbl-victim-sex-table shows that most victims of homicide are male with 1,721 solved cases and 3,903 unsolved cases in comparsion to female victims with 335 solved cases and 348 unsolved cases. The proportion of cases with arrest and not is almost equal for homicides with female victims at 49% and 51%, respectively. On the other hand, the proportion of cases with arrest (31%) and not (69%) has a 38% difference for homicides with female victims. 

\newpage
### Victim's Race 
```{r}
#| label: fig-victim-race-bar
#| fig-cap: "Number of homicide cases per race in Chicago and Los Angeles (2010 to 2017)"
#| echo: false
#| warning: false
#| message: false

number_of_cases_victim_race <- 
  analysis_data_homicides |>
  # Group by victim's race 
  group_by(victim_race) |>
  # Count number of solved and unsolved homicides for each race
  count(arrest_was_not_made)|>
  # Rename count column
  rename(
    "num_of_cases_victim_race" = n
  ) |>
  mutate(
    arrest_was_not_made = case_when(
      (arrest_was_not_made == 1) ~ "Arrest was not made",
      (arrest_was_not_made == 0) ~ "Arrest was made",
      TRUE ~ "None")
  ) 

number_of_cases_victim_race |>
  ggplot(mapping = aes(x = victim_race, y = num_of_cases_victim_race)) +
  # Creates two graphs based on the status of the case
  facet_wrap(facets = vars(arrest_was_not_made)) +
  geom_bar(stat = "identity", fill = "#a4ac86") +
  theme_minimal() +
  labs(x = "Victim's Race", y = "Number of cases") +
  theme(legend.position = "bottom")
```

```{r}
#| label: tbl-victim-race-table
#| tbl-cap: "Number of homicide cases per sex in Chicago and Los Angeles (2010 to 2017)"
#| echo: false
#| warning: false
#| message: false

number_of_cases_victim_race |>
  rename(
    "Victim's race" = victim_race, 
    "Status of the homicide case" = arrest_was_not_made,
    "Number of cases" = num_of_cases_victim_race
  ) |>
  kable()
```

From @fig-victim-race-bar and @tbl-victim-race-table, they show that there were more homicide case solved when the victims identified as "White" (191 cases), "Asian" (22 cases), and "Other" (41 cases). However, a disproportionate number of homicide cases have victims who are Black or Hispanic. For both Black and Hispanic victims, they have more homicide cases that go unsolved with 2,960 and 1,064 cases compared to homicide cases that are solved with 1,103 and 699 cases, respectively.

\newpage
## Model Results {#sec-model-results}
```{r}
#| label: tbl-model-result
#| tbl-cap: Relationship between a homicide being unsolved from 2010 to 2017 with the city and year a victim is found in/on and the race, age, and sex of a victim. Mean absolute deviation (MAD) values are in parenthesis.
#| echo: false
#| warning: false
#| message: false

modelsummary(
  # List out unsolved_model_results information
  list("Unsolved homicides (2010 to 2017)" = unsolved_model_results),
  # Specify MAD as the statistic
  statistic = "mad"
)
```

```{r}
#| label: fig-model-result-ci
#| fig-cap: The credible intervals (line) for coefficient estimates (dot) of predictor variables for homicides that go unsolved from 2010 to 2017.
#| echo: false
#| warning: false
#| message: false
# Specify credible interval to be 90% and present model results
modelplot(unsolved_model_results, conf_level = 0.9) +
  labs(x = "90 per cent credible interval")
```
@tbl-model-result and @fig-model-result-ci presents the results from our logistic regression model in the Bayesian framework and the 90% credible intervals of each predictor, respectively. From @tbl-model-result, the intercept $\beta_0$ of -165.865 indicates that when the homicide victim is White, since "White" is the baseline for the victim_race predictor, and victim_age is 0 and year being 2010 with its coefficient being 0 and the victim's sex is female, the homicide is more likely to be solved. @tbl-model-result indicates that the coefficient estimate of victim_race $\beta_1$ is 0.168 when the victim is Asian. This means that the log-odds of a homicide case being unsolved increases by 0.168 when the victim is Asian while other predictor variables stays fixed. Following this, when the victim's race is Black or Hispanic, the log-odds of a homicide being unsolved increases by 0.567 and 0.434, respectively. This indicates that the likelihood of a homicide going unsolved increases if the victim's race is Asian, Black, or Hispanic relative to a victim's race being White. On the other hand, when the victim's race falls under "Other", the log-odds of a homicide case being unsolved decreases by 0.296. This indicates that the likelihood of a homicide being unsolved decreases if the victim's race falls under "Other" relative to a victim's race being White. However, since the 90% credible interval for the coefficient estimate of victim_race appears to be close 0 as seen in @fig-model-result-ci, this means that a victim's race has a weak likelihood of impacting the outcome of their case being unsolved. 

@tbl-model-result shows that since the coefficient estimate of victim_age $\beta_2$ is -0.006, this means the log-odds of a homicide case being unsolved decreases by 0.006 when the age of the victim increases by 1 year as other predictor variables stay constant. This means victims of unsolved homicides are likely on the more younger side. @fig-model-result-ci also indicates that $\beta_2$'s 90% credible interval is close to 0 or includes 0 in its interval, indicating there is a chance the victim's age does not have an influence the outcome of a homicide case being unsolved. With the coefficient estimate of victim_sex $\beta_3$ being 0.662 in @tbl-model-result, it indicates that the log-odds of a homicide case being unsolved increases by 0.662 when the victim is male while other predictors are fixed. This suggests that the likelihood of the a homicide case being unsolved increases when the victim is a male. Looking at @fig-model-result-ci, the credible interval for $\beta_3$ is also slightly above 0. @tbl-model-result also shows that the log-odds of a homicide being unsolved decreases by 1.089 as indicated by the coefficient estimate $\beta_4$ when city is set to Los Angeles with other predictors being fixed. This indicates that more unsolved homicide cases are likely to occur in Chicago instead. @fig-model-result-ci also shows that $\beta_4$'s credible interval is below 0. Looking at the year predictor and its coefficient estimate, the log-odds of a homicide case being unsolved increases by 0.083 as noted by the coefficient estimate $\beta_5$ when the year increases by 1 year while the other predictors stay constant. This indicates that cases are more likely to be unsolved in the later years between 2010 to 2017. @fig-model-result-ci also shows that $\beta_5$'s credible interval is slightly above 0 or includes 0 indicating that the year has a weak likelihood of indicating if a homicide is unsolved. 


\newpage
# Discussion {#sec-discussion}

In @sec-results, we analyzed homicide case information like the victim's age, sex, and race and the year and city the homicide case occurred to see if there were any differences between homicide case information between unsolved and solved homicides from the year 2010 to 2017. We also built a Bayesian logistic regression model in @sec-model-results, to see the likelihood of the homicide case information impacting the homicide case outcome of going unsolved. 

## Chicago likely to have more unsolved homicides than Los Angeles with a surge in unsolved cases from 2016 onwards

From @fig-city-bar and @tbl-city-table, it indicates that while Los Angeles have slightly more homicide cases that are solved than unsolved, 77% of Chicago's homicide cases are unsolved from 2010 to 2017. This is also seen in @tbl-model-result, where our model indicates that that unsolved homicides in Chicago are likely to go unsolved compared to Los Angeles. This implies potential issues with how the Chicago Police Department is managing homicide case closure. From @fig-month-bar and @fig-year-bar, we saw that most unsolved homicide cases occur in the middle and later half of the year and that there was jump in unsolved homicides in 2016 and 2017 compared to past years. @citeCNNChicago reported on January 2, 2017 that 2016 was the year with the most number homicides in the past 19 years due to gun violence in the city. This suggest that most of the unsolved cases could have occurred due to police departments like the Chicago Police Department being unable to keep up with the surge of homicide cases. 

## Age of the homicide victim likely does not impact the outcome of their case being unsolved however their gender may 

@fig-victim-age-histogram indicates that the age of the homicide victim likely does not impact the outcome of their case be unsolved due to the uniformity of the distribution of ages. This is further seen in @fig-model-result-ci, where there is a chance the victim's age does not influence the outcome of a homicide case in our model. This implies that the age of the homicide victim does not impact if their case is unsolved or not. However, @fig-model-result-ci and @fig-victim-sex-bar indicates that female victims had a higher proportion of their homicide cases being solved while on the otherhand, male victims had a higher proportion of their homicide cases going unsolved. This suggest that males are more likely to have their case go unsolved.  

## Disportionate number of homicide victims in unsolved cases in Chicago and Los Angeles from 2010 to 2017 are Black and Hispanic

From @fig-victim-race-bar and @tbl-victim-race-table it shows that Black and Hispanic victims make up more than 1,000 unsolved cases compared to other victims of other races who have under 1,000 unsolved cases. However, Black victims makes up the majority of unsolved homicide at 2960 cases with only 1103 solved homicides. Based on @tbl-model-result and @fig-model-result-ci, our model shows that there is a slight likelihood that being Black and Hispanic relative to being White impacts a homicide case going unsolved. @citeChavis had found that the Chicago Police Department was under scrutiny for another issue with their gang databases being inaccurate and targeting mostly Black and Latinx residents. @citeChavis also mentions that Chicago is one of the United States' most segregated cities both economically and racially. This suggest that Black and Hispanic victims could be facing systematic biases in homicide case closures and their cases being solved. 


## Areas of improvement

The dataset used in the paper was compiled in 2018 and we currently do not know which homicide cases have been solved as of 2024, which limits the years we were able to analyze. There are other factors like the resources of the police department that could have also impacted the outcome of homicides being unsolved, which we did not have information on and that could have reduced the accuracy of our model. Since some information in the dataset was aggregated by humans from not only FBI data but also papers, human error could have occur when inputting information into the data. For future works on unsolved homicides, we recommend compiling a new dataset for the years 2018 to 2024 similar to what The Washington Post did and considering other factors like the resources of the police departments [@datahomicides]. 

\newpage

\appendix

# Appendix {#sec-appendix}

## Dashboard for Interactive Visualizations

A dashboard containing interactive versions of the graphs found in this paper was developed using shiny [@citeshiny], shinydashboard [@citeshinydashboard], and plotly [@citeplotly]. The link to the shiny app can be found here: [https://49z7k8-emily-su.shinyapps.io/unsolved-homicides-app/](https://49z7k8-emily-su.shinyapps.io/unsolved-homicides-app/).

## Note on Reproducing

In order to reproduce the results in the paper, first run the 00-install_packages.R in the scripts folder located in this paperâ€™s GitHub repository. Then run the other scripts based on the number at the beginning of the script name.

## Acknowledgments

We would like to thank @citetellingstories for providing assistance with the R code used to produce the tables and graphs in this paper.

## Note on Code styling

Code written in the scripts was checked and styled with lintr [@citelintr] and styler [@citestyler].

## Additional Tables

```{r}
#| label: tbl-month-table
#| tbl-cap: "Number of solved and unsolved homicides across the 12 months of a year in Los Angeles and Chicago (2010 to 2017)"
#| echo: false
#| warning: false
#| message: false

# Create table for the number of cases per month
number_of_cases_month |>
  rename(
    "Month" = month,
    "Status of the homicide case" = arrest_was_not_made,
    "Number of cases in the month" = num_of_cases_month
  ) |>
  kable()
```


```{r}
#| label: tbl-year-table
#| tbl-cap: "Number of solved and unsolved homicides from 2010 to 2017 in Los Angeles and Chicago"
#| echo: false
#| warning: false
#| message: false

# Create table for dataframe pertaining to the number of cases per year
number_of_cases_year |>
  rename(
    "Year" = year,
    "Status of the homicide case" = arrest_was_not_made,
    "Number of cases in the year" = num_of_cases_year
  ) |>
  kable()
```

\newpage
## Idealized Survey and Methodology {#sec-ideal-survey}

### Idealized Survey Objectives
The objective of our survey is to obtain information about the investigators from US police departments and their experience with dealing with homicide cases. This information would be used to take into account any potential factors about police officers that could potentially impact if a homicide case ends up unsolved. Currently, we only have state collected homicide data that is collected by the FBI with basic demographic, temporal, and geographic information. @citeJohnson looked at prison data and noted that the standards in place with state collected data do not help us fully understand the cause and impact of the US prison system. The data collected often only looked at the individuals in prison and not considered structural factors like the public's opinion to crime policies [@citeJohnson]. This can also be applied to homicide data where we can not say we fully understand the cause of homicide cases going unsolved by only looking at the victim's characteristics and where they were found. Thus, this led us to conducting this survey to further understand the crime case system better and what interventions may be needed, which is also noted by @citeJohnson on community sourced prison data. Community source data involves obtaining data from the people living in or with the system itself, as defined by @citeJohnson, and in our case, our survey aims to collect data from people who maintain the homicide case system. In the following idealized methodology, we will cover our sampling approach and respondent recruitment, data validation, the design of our survey, limitations of our survey, a link to how the survey could look, and the survey questions themselves. 

### Sampling Approach and Respondent Recruitment

Our target population are all investigators from US police departments as defined by [@citetellingstories]. However, since we can not survey every investigator in the US, we will narrow down our group to be investigators from 5 US police department across the United States who are responsible for homicide cases and are located in large cities, which is our sampling frame. More specifically, our sample will be all the investigators from 5 US police department in large cities who are responsible for homicide cases and who we can gather data on [@citetellingstories].

The sampling approach we plan to take is a mix of non-probabilistic and probabilistic sampling. Conducting non-probabilistic sampling would ensure that we are obtaining the necessary information from police departments in more populated cities [@citetellingstories]. However some limitations with non-probabilistic sampling is that our findings from the survey might not generalize to other police departments nationwide [@citetellingstories]. We also plan to conduct probabilistic sampling within the non-probabilistic sample we have so that any person in our sampling frame has a chance of being picked for to complete our survey [@citetellingstories]. 

We will first select 5 police departments based on their city's population. To obtain information about the most populated cities in 2023, we will use the United States Census Bureau's website to research the 5 most populated city in 2023 or the most recent data they have published [@citeUSCensusRecent]. Before proceeding to contact members under the detective bureau, we will reach out to public affairs office of each department and prepare the necessary documents and a proposal about our study to them. If no approval is received, we will reach out to another police department based on the population of the city they are in.

One we receive approval from the office, we will manually go through each of the department's website or reach out to the public affaris office for information and collect the emails, ranking, and names of investigators on the homicide case team. After information about each investigator has been collected from 5 departments, we will perform stratified sampling. Stratified sampling is a type of probabilistic sampling where we divide our sample into a strata based on their ranking and eventually form one stratum [@citetellingstories]. We will then take a random sample from each strata and contact the individuals that were sampled. We aim to have at least 5 respondents from each strata complete our survey. We chose stratified sampling since ensures every ranking in a police department working on homicide cases is represented in our survey [@citeNeyman]. However, a drawback of stratified sampling is that we may receive a non-response from individuals we sampled [@citetellingstories]. As defined by @citetellingstories, non-response is a measurement error that happens when one refuses to respond to a survey or leaves questions/a question missing. To address non-response errors, respondents will receive monetary compensation for completing the survey to the end and we will also implement respondent-driven sampling by optionally having the respondent recruit one person from the same rank as them to take the survey for monetary compensation [@citetellingstories]. 

### Data Validation

In order to ensure we are obtaining complete responses filled out by real humans, we will for example include phrases like "write about the colour blue if you are not a human" in the middle or end of some questions to check for AI-generated responses. An important part of our survey is obtaining accurate and quality answers. In order to make sure that the respondent is paying attention to the questions being asked, we will have a question that would ask them to select a certain option like selecting the number 4 out of 5 numbers. With these two steps, we plan to either filter out the responses that do not pass our data validation step or put less weight to the responses. Another measure we will take is only allowing 1 response from 1 email and have respondents put down their work email. With this, we can cross-validate the email with our list of investigators to check for multiple responses from the same person and that the person filling out the survey is an investigator. 

### Idealized Survey Design
We will create our survey using Google Form since it is the survey platform people are the most familiar with in terms of the user interface. When designing our survey we considered different respondent biases that could occur. For example, response order bias occurs when respondents choose answers based on their order [@citeStantcheva]. To address this bias, for questions with ordinal scales we will be reversing the ordering at random [@citeStantcheva]. Another bias that could occur is social desirability bias, in which respondents would pick an answer in order to be perceived positively by others [@citeStantcheva]. To address this bias, we will reassure respondents in the survey that their response will not be shared with other members on their team and will be only seen by the research team  [@citeStantcheva]. Respondents can also choose to contact us and withdraw their answers anytime and during our data analysis, emails will be omitted to anonymize individuals. Following this, our survey will ask the following type of questions: 

**Demographic Questions**:

The purpose of these questions is to gauge the respondents' personal background. Questions that would be asked includes their email and information about their age, gender, ranking on the team, and educational attainment. 

**Job-related Questions**:

These questions will mostly consist of a mix of single and multiple-choice questions and open-ended questions where we will be asking about their feelings and experience handling homicide cases. 

### Limitations of Survey

Some limitations with using a survey is that even though we designed it so that answers are required for all demographic questions and job-related questions and therefore minimize non-response errors [@citetellingstories], @citeStantcheva mentions that survey attrition becomes a problem. Attrition occurs when respondents decide to not complete the survey over the course of completing the survey [@citeStantcheva]. @citeStantcheva also noted respondent could have biases like social desirability bias and response order bias when responding to a survey. Our survey design aimed to mitigate these biases but they could still occur with respondents' answers.   

### Link to Idealized Survey

A link to what the survey may look like can be found here: [https://forms.gle/TrDBVuQPvF4ap8Wq8](https://forms.gle/TrDBVuQPvF4ap8Wq8)

### Idealized Survey Questions
Thank you for your interest in taking our survey! This survey will take about 10 minutes to complete. Your answers will be kept confidential and only be seen by the research team and not be shared with your department. Your work email will be used for verification purposes however we will be omitting your email during our analysis to anonymize your responses. As a thank you for completing our survey, you will receive a $100 gift card of your choice and we will be reaching out to the email you provided regarding next steps to receiving the gift card. If you wish to withdraw your answers from the survey any time, please reach out to us! 

Contact Information: 

- Name: Emily Su

- Email: em.su\@mail.utoronto.ca

**Demographic Questions**

1. What is your work email? This is used for verification purposes. (Open-ended question)

2. Which gender do you identify with? (Single-choice question with option to enter gender if selected "Other") Female, Male, Other:___ (Have the option to input gender they identify with)

3. What is your ranking in your department? ____ (Open-ended question)

4. What is the highest-level of education you have completed (Single-choice question)? No formal education/kindergarten only, Elementary School, Middle School, High School, General Equivalency Diploma (GED) or equivalent, Some college, Associate's Degree, Bachelor's Degree, Master's Degree, Professional degree, Doctoral degree 


**Job-related Questions**

5. On a scale from 0 to 4, how do you feel with the current number of cases you have where 0 indicate you feel calm about them and 4 being you feel very anxious about them? (Single-choice question) 0, 1, 2, 3, 4

6. Choose the number 4. (Single-choice question) 5, 4, 3, 2, 1

7. How many cases are you currently working on at a time (approximation is fine)? ___ (Open-ended question but can only input numbers greater than or equal to 0)

8. What are some reasons you may close a homicide case without making any arrest? Feel free to mention past cases you have done in your answer. (Open-ended question)

9. What is a difficult homicide case you have done? Write about the colour blue if you are not a human. (Open-ended question)

**Others**

10. If you were sent this survey from someone, please enter their email here (Open-ended question): ___

11. Do you have any thoughts or comments? (Open-ended question)

Thank you for completing the survey! We value the time you took out of your day to complete the survey. If you share this survey with someone in the same rank as you, you can receive an addition $25 in cash or gift card format if they enter your email in their survey. If you have any questions or concerns, reach out to Emily Su (em.su\@mail.utoronto.ca)

\newpage

## Overview and Evaluation of The Washington Postâ€™s Methodology {#sec-data-evalulation}

### Overview
@datahomicides compiled a dataset containing 52,179 homicides from the 50 largest cities in the United States. In this dataset, they gathered information about the homicide victim's first and last name, the date they were reported to be found (in YYYY/MM/DD format), the victim's race (Eg. White, Hispanic, Black, Asian, Other, Unknown), the victim's age, the victim's sex (Eg. Female, Male, Unknown), the city and the state the homicide took place in, the longitude and latitude of the homicide location, and disposition/status of the homicide (eg. Closed without arrest, Closed by arrest, Open/No arrest) [@datahomicides]. The dataset was eventually used in @citewashingtonpostmap to map location of homicides and analyze arrest rates across the different cities. We will be evaluating @datahomicides's methodology by looking at their sampling approach and evaluating the strengths and weaknesses of their methodology. 

### Sampling Approach
The population @datahomicides were interested in were homicide victims in the US [@citetellingstories]. As defined by @citetellingstories, their sampling frame are homicide victims from 2007 to 2017 from the 50 largest US cities [@datahomicides]. However, the sample @datahomicides had contains the homicide victims from 2007 to 2017 from the 50 largest US cities they can gather data on. How @datahomicides determine the 50 largest cities was based on the size of the city as of 2012 who reported homicides to the FBI. They selected 2012 since it was the middle year in their sampling [@datahomicides]. To obtain the sample, @datahomicides started by gathering homicide data collected by the FBI that can be accessed through the UCR publications page on the FBI website from 2007 to 2012 of the 50 largest cities [@citeFBIinfo]. 

The UCR program originally had a system until 2021 called the Summary Reporting System (SRS), which obtained details about different crimes such as victim information taking place that are reported by law enforcement agencies nationwide [@citeFBIinfo]. @datahomicides obtained their data collected through the Summary Reporting System (SRS). As noted in @sec-data, police agencies have different methods of collecting homicide crime data. The Chicago Police Department has a digital system called CLEAR (Citizen Law Enforcement Analysis and Reporting), where they would enter in the victim's details, the location of the crime, and if an arrest was made or not once a homicide is reported [@citeChicagoPolice]. This information is then reported to the FBI through the UCR program monthly [@citeChicagoPolice]. On the other hand, The Los Angeles Police Department would initially handwrite a physical report about the crime with details such as the type of crime, the premise the crime occured at, and the age and ethnicity of the victim [@citeLApolice]. On a monthly basis, the information will be transcribed into a digital format to be sent to the FBI  [@citeLApolice]. 

Since the FBI collect data on different crimes other than homicide, @datahomicides used the UCR's definition of homicides, which is defined to be "murder and non-negligent manslaughter but exclude suicides, accidents, justifiable homicides and deaths caused by negligence", to filter for only homicides [@datahomicides]. To ensure the validity of the homicide counts and closure rates in the FBI data, they check with other pieces of data such as papers [@datahomicides]. However, not all police departments give all information about homicides leading to non-response bias [@citetellingstories]. To address this, they used court records, medical examination reports, and death certificates they gathered to fill in missing information [@citetellingstories]. However, there are cases where the police department is not able to identify the victim's sex, age, and/or race or the police does not indicate the specific location the homicide occurred. In these cases, the value for a victim's characteristic (sex, age, race) is indicate as "Unknown" and for geographic information that is missing, it is left blank [@datahomicides]. With the sample they had, @datahomicides would indicate if a homicide case is "Closed by arrest" if the police indicates an arrest was made and a case as "Closed without arrest" means that there is evidence of who the perpetrator could be but an arrest was not possible. All other type of cases are marked as "Open/No arrest" [@datahomicides]. 

The sampling approach taken by The Washington Post [@datahomicides] is non-probabilistic sampling and more specifically, purposive sampling [@citePurposiveSampling]. @datahomicides were interested in homicide cases from 2007 to 2017 from the 50 largest US cities and purposive sampling would allow them to have a sample that fit their sampling frame. However, @citePurposiveSampling noted that a tradeoff of purposive sampling is that it is prone to research bias since researchers have to make judgement such as the size of the sample and why. For example, why is it that The Washington Post decided to choose the 50 largest US cities instead of the 20 largest US cities? 

### Strengths and limitations
Some strengths with The Washington Post's methodology is that they used the most comprehensive data out there about US homicides, which is the one from the FBI. Another strength about their methodology is that they addressed gaps in the data using court records for example and also validating the FBI's data with papers on homicide clearance rates and counts [@datahomicides]. However, a weakness of their sampling was the subjectivity surrounding the chose for the number of cities and why the largest 50 cities. Also another limitation with the sampling is that since their dataset is large, it is possible that the status of the homicide could have changed after they have finalized the dataset. Since @datahomicides are not directly asking police department for information, it is possible that the FBI could have left information out intentionally and it increases the complexity of their methodology to fill in the gap. 

\newpage


## Model details {#sec-model-details}

### Variance Inflation Factor

@tbl-vif shows that the VIF for the predictor variables are close to 1. When the VIF is 1 it indicates there is no correlation between a predictor variable and other predictors in the model [@citeVIFarticle]. Since VIF values are close to 1 for all predictors, it indicates there is little correlation amongst the predictor variables.  
```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: tbl-vif
#| tbl-cap: "Valence inflation factor (VIF) of each predictor for unsolved homicide model from 2010 to 2017"

# Referenced: https://www.bookdown.org/rwnahhas/RMPH/mlr-collinearity.html
vif(unsolved_model_results) |>
  kable()
```


### Posterior predictive check

In @fig-ppcheckandposteriorvsprior, the posterior predictive check shows that the actual data follows the same curve as the posterior distribution of the fitted model and thus is consistent with it [@citetellingstories]. 

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-ppcheckandposteriorvsprior
#| layout-ncol: 1
#| fig-cap: "How the data affects the fit of the unsolved homicide model"
#| fig-subcap: ["Posterior prediction check for the unsolved homicide model"]

pp_check(unsolved_model_results) +
  theme_classic() +
  theme(legend.position = "bottom")
```


### Diagnostics

Using the checks mentioned by @citetellingstories, @fig-stanareyouokay shows that no issues were encountered while the Markov Chain Monte Carlo (MCMC) algorithm was sampling from the posterior distribution of our model. The line bouncing horizontally and there being an overlap between chains in the trace plot and the estimates being close to 1 and less than 1.1 in the rhat plot indicates the MCMC algorithm converged properly and there is nothing unusual [@citetellingstories]. 

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-stanareyouokay
#| fig-cap: "Checking the convergence of the Markov Chain Monte Carlo (MCMC) algorithm for the unsolved homicide model"
#| fig-subcap: ["Trace plot", "Rhat plot"]
#| layout-ncol: 2

plot(unsolved_model_results, "trace")

plot(unsolved_model_results, "rhat")
```


\newpage


# References


